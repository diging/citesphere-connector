{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f275807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "import constants as const \n",
    "from authentication import AuthObject\n",
    "from CitesphereConnector import CitesphereConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0597b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_object = AuthObject()\n",
    "auth_object.authType  = 'oauth'\n",
    "auth_object.access_token = \"f5f7e899-30d3-4531-8b2e-8009e9969ed4\"\n",
    "citesphere_api_url = const.CITESPHERE_API_URL\n",
    "connector = CitesphereConnector(citesphere_api_url, auth_object)\n",
    "#default max number of items displayed on a collection items page in citesphere\n",
    "max_size=const.MAX_SIZE\n",
    "\n",
    "def get_file(file_id:str)-> str:\n",
    "    return const.GILES_URL+\"{}/content\".format(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b875485a",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "groups is a list of dictionaries contains information about the different groups of collections \n",
    "with following properties:\n",
    "\n",
    "{'id': ,\n",
    "  'name': '',\n",
    "  'version': ,\n",
    "  'created': <date>,\n",
    "  'lastModified': <date>,\n",
    "  'numItems': ,\n",
    "  'owner': ,\n",
    "  'type': '',\n",
    "  'description': '',\n",
    "  'url': '',\n",
    "  'syncInfo': }\n",
    "  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc3bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=connector.get_groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc60a46",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "this following function \"download_files(folder_path:str,ids:set, citesphere_token:str) -> list\":\n",
    "\n",
    "has following parameters:\n",
    "\n",
    "1. folder_path:str = location of the folder where the user wants to save the downloaded files\n",
    "\n",
    "2. ids:set = set of tuples, containing pair of file ids and file names\n",
    "\n",
    "3. citesphere_token:str = token to access data from giles\n",
    "\n",
    "function:\n",
    "this function iterates throught the ids list of tuples, plugging the file id to the giles url string to get the\n",
    "file url from giles for downloading the file to the dedicated folder.\n",
    "\n",
    "Append the path to the path_list.\n",
    "\n",
    "if the response of the get request is of level 200\n",
    "it writes the file with the appriate content and save it to the download folder and *returns* the list of the path\n",
    "for the downloaded files, so that it can be saved to the csv file's path field.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d91846ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download files from the collection items\n",
    "def download_files(folder_path:str,ids:set, citesphere_token:str) -> list:\n",
    "    \n",
    "    #stores paths to downloaded files\n",
    "    path_list = []\n",
    "    \n",
    "    #iterating through the ids list\n",
    "    for (file_id, file_name) in ids:\n",
    "        \n",
    "        # getting the file ur using giles file id\n",
    "        giles_url = get_file(file_id)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        filename = os.path.join(folder_path, f\"{file_name}\")\n",
    "        \n",
    "        #append the path of the saved file to the folder\n",
    "        path_list.append(filename)\n",
    "        \n",
    "        #header for get request\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {citesphere_token}\",\n",
    "            \"Content-Type\": \"application/pdf;charset=UTF-8\"\n",
    "            }\n",
    "        response = requests.get(giles_url, headers=headers)\n",
    "        \n",
    "        #saving the file if retrieved successfully\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "    return path_list "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6df1dd6",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "The following function \"get_set(items_list: list) -> set:\" \n",
    "Get a set of file IDs and names from the collection items.\n",
    "\n",
    "Parameters:\n",
    "items_list (list): List of items containing information about files.\n",
    "\n",
    "Returns:\n",
    "set: Set of tuples containing pairs of file IDs and file names.\n",
    "\n",
    "Functionality:\n",
    "This function iterates through the 'items_list' and extracts file IDs and names from different fields such as\n",
    "'uploadedFile', 'extractedText', 'pages', 'image', 'text', 'ocr', and 'additionalFiles'. It creates a set of\n",
    "tuples with file IDs and names and returns the resulting set.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc9366",
   "metadata": {},
   "source": [
    "\"\"\"# Get a set of file IDs and names from the collection items\n",
    "def get_set(items_list: list) -> set:\n",
    "    ids = set()\n",
    "\n",
    "    for values in items_list:\n",
    "        # Getting the file IDs in uploadedFile, extractedText, pages, image, text, ocr, additionalFiles\n",
    "        ids.add((values[\"uploadedFile\"][\"id\"], values[\"uploadedFile\"][\"filename\"]))\n",
    "\n",
    "        # Check if extractedText is present and not equal to \"None\"\n",
    "        if values[\"extractedText\"] and values[\"extractedText\"] != \"None\":\n",
    "            ids.add((values[\"extractedText\"][\"id\"], values[\"extractedText\"][\"filename\"]))\n",
    "\n",
    "        # Check if pages is present and not equal to \"None\"\n",
    "        if values[\"pages\"] and values[\"pages\"] != \"None\":\n",
    "            for value in values[\"pages\"]:\n",
    "                ids.add((value[\"image\"][\"id\"], value[\"image\"][\"filename\"]))\n",
    "                ids.add((value[\"text\"][\"id\"], value[\"text\"][\"filename\"]))\n",
    "                ids.add((value[\"ocr\"][\"id\"], value[\"ocr\"][\"filename\"]))\n",
    "\n",
    "                # Iterate through additionalFiles in pages\n",
    "                for file in value[\"additionalFiles\"]:\n",
    "                    ids.add((file[\"id\"], file[\"filename\"]))\n",
    "\n",
    "    return ids\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f795a08",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "The following function write_to_csv(csv_name: str, item: list, flag: int) -> None:\n",
    "Write metadata to a CSV file.\n",
    "\n",
    "Parameters:\n",
    "1. csv_name (str): Name of the CSV file.\n",
    "2. item (list): List containing metadata and file path.\n",
    "3. flag (int): Flag to determine whether to write the fields at the top of the file.\n",
    "\n",
    "Returns:\n",
    "None\n",
    "\n",
    "Functionality:\n",
    "This function writes metadata to a CSV file. It uses a flag to decide whether to write the fields at the top of\n",
    "the file. If the flag is 0, it writes the fields; otherwise, it writes the values. It appends the data to the\n",
    "existing CSV file.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63766c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CSV file with all the metadata and file path of the downloaded files\n",
    "def write_to_csv(csv_name: str, item: list, flag: int) -> None:\n",
    "\n",
    "    with open(csv_name, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Check if it's the first time writing to the file\n",
    "        if flag == 0:\n",
    "            fields = list(item.keys())\n",
    "            writer.writerow(fields)\n",
    "\n",
    "        # Write the values to the CSV file\n",
    "        writer.writerow(list(item.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed58199e",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "The following function add_to_csv(csv_name: str, folder_name: str, items: list, csv_dict: dict, flag: int) -> int:\n",
    "Add items to a dictionary object 'csv_dict' that contains all the collection items, with metadata and\n",
    "downloaded file path.\n",
    "\n",
    "Parameters:\n",
    "1. csv_name (str): Name of the CSV file.\n",
    "2. folder_name (str): Name of the folder where the files will be downloaded.\n",
    "3. items (list): List of collection items.\n",
    "4. csv_dict (dict): Dictionary containing collection items with metadata and file paths.\n",
    "5. flag (int): Flag to determine whether to write the fields at the top of the file.\n",
    "\n",
    "Returns:\n",
    "int: Updated flag value.\n",
    "\n",
    "Functionality:\n",
    "This function iterates through the collection items in 'items'. For each item, it checks if the item's key\n",
    "already exists in 'csv_dict'. If not, it adds the item to 'csv_dict' with a unique key and sets the 'paths'\n",
    "property to an empty string. If 'gilesUploads' are present in the item, it gets the set of file IDs and names,\n",
    "downloads the files, and updates the 'paths' property accordingly. The function then writes the item to the\n",
    "CSV file using the 'write_to_csv' function and updates the flag. Finally, it returns the updated flag value.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37167759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_csv(csv_name: str, folder_name: str, items: list, csv_dict: dict, flag: int) -> int:\n",
    "\n",
    "    for item in items[\"items\"]:\n",
    "        if item[\"key\"] in csv_dict:\n",
    "            continue\n",
    "        item[\"paths\"] = \"\"\n",
    "\n",
    "        # Check if gilesUploads are present\n",
    "        if item[\"gilesUploads\"]:\n",
    "            giles_ids = set()\n",
    "\n",
    "            items_list = item[\"gilesUploads\"]\n",
    "\n",
    "            for values in items_list:\n",
    "                # Getting the file IDs in uploadedFile, extractedText, pages, image, text, ocr, additionalFiles\n",
    "                if values[\"uploadedFile\"] and values[\"uploadedFile\"] != \"None\":\n",
    "                    giles_ids.add((values[\"uploadedFile\"][\"id\"], values[\"uploadedFile\"][\"filename\"]))\n",
    "\n",
    "                # Check if extractedText is present and not equal to \"None\"\n",
    "                if values[\"extractedText\"] and values[\"extractedText\"] != \"None\":\n",
    "                    giles_ids.add((values[\"extractedText\"][\"id\"], values[\"extractedText\"][\"filename\"]))\n",
    "\n",
    "                # Check if pages is present and not equal to \"None\"\n",
    "                if values[\"pages\"] and values[\"pages\"] != \"None\":\n",
    "                    for value in values[\"pages\"]:\n",
    "                        giles_ids.add((value[\"image\"][\"id\"], value[\"image\"][\"filename\"]))\n",
    "                        giles_ids.add((value[\"text\"][\"id\"], value[\"text\"][\"filename\"]))\n",
    "                        giles_ids.add((value[\"ocr\"][\"id\"], value[\"ocr\"][\"filename\"]))\n",
    "\n",
    "                        # Iterate through additionalFiles in pages\n",
    "                        for file in value[\"additionalFiles\"]:\n",
    "                            giles_ids.add((file[\"id\"], file[\"filename\"]))\n",
    "\n",
    "            if giles_ids:\n",
    "                # store paths of the downloaded files to the path attribute\n",
    "                item[\"paths\"] = download_files(folder_name, giles_ids, auth_object.access_token)\n",
    "\n",
    "        # Add the item to csv_dict and write it to the CSV file\n",
    "        csv_dict[item[\"key\"]] = item\n",
    "        write_to_csv(csv_name, item, flag)\n",
    "        flag = 1\n",
    "\n",
    "    return flag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f69c4",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "The following function downloads and generates a CSV file with all the meta data\n",
    "Downloads and generates a CSV file containing all the group items information.\n",
    "\n",
    "Parameters:\n",
    "1. csv_name (str): Name of the CSV file.\n",
    "2. folder_path (str): Name of the folder where the files will be downloaded.\n",
    "3. groups (list): List of group information.\n",
    "4. connector: Connector object to interact with the data source.\n",
    "5. max_size (int): Maximum size for each page of items.\n",
    "\n",
    "Returns:\n",
    "dict: Dictionary containing collection items with metadata and file paths.\n",
    "\n",
    "Functionality:\n",
    "This function iterates through the 'groups'. For each group, it gets the collections and then retrieves items\n",
    "from each collection. It calls the 'add_to_csv' function to add the items to a dictionary 'csv_dict' and write\n",
    "them to the CSV file. The function returns 'csv_dict' containing all the collection items with metadata and\n",
    "file paths.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "229c7e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Downloads and generates a CSV file containing all the group items information\n",
    "def process_groups(csv_name: str, folder_path: str, groups: list, connector, max_size: int) -> dict:\n",
    "\n",
    "    csv_dict = {}\n",
    "    flag = 0\n",
    "    \n",
    "    #Iterate over the groups\n",
    "    for group in groups:\n",
    "        group_id = group[\"id\"]\n",
    "        collections = connector.get_collections(group_id)\n",
    "        \n",
    "        #Iterate over the collections in the respective group\n",
    "        for collection in collections[\"collections\"]:\n",
    "            num_pages = math.ceil(collection[\"numberOfItems\"] / max_size)\n",
    "            \n",
    "            #Iterating over the pages\n",
    "            for page in range(1, num_pages + 1):\n",
    "                items = connector.get_collection_items(group_id, collection[\"key\"], page)\n",
    "                flag = add_to_csv(csv_name, folder_path, items, csv_dict, flag)\n",
    "\n",
    "    return csv_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42eaa42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_filename = \"citesphere_csv.csv\"\n",
    "\n",
    "folder_path  = \"Files\"\n",
    "\n",
    "process_groups(csv_filename,folder_path,groups,connector,max_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020b025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
