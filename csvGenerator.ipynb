{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f275807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "from CitesphereConnectorTest import *\n",
    "from CitesphereConnector import CitesphereConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c0597b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_object = authObject()\n",
    "auth_object.authType  = 'oauth'\n",
    "auth_object.access_token=\"access-token\"\n",
    "connector = CitesphereConnector(\"https://diging-dev.asu.edu/citesphere-review/api\", auth_object)\n",
    "groups=connector.get_groups()\n",
    "#default max number of items displayed on a collection items page \n",
    "max_size=50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37167759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download files from the collection items\n",
    "def download_file(folder_path:str,ids:set, citesphere_token:str,):\n",
    "    path_list = []\n",
    "    for (file_id, file_name) in list(ids):\n",
    "        giles_url = f\"https://diging.asu.edu/geco-giles-staging/api/v2/resources/files/{file_id}/content\"\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        filename = os.path.join(folder_path, f\"{file_name}\")\n",
    "        path_list.append(filename)\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {citesphere_token}\",\n",
    "            \"Content-Type\": \"application/pdf;charset=UTF-8\"\n",
    "            }\n",
    "        response = requests.get(giles_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "    return path_list  \n",
    "\n",
    "#Returns the set of tuples containing, file_ids and file_name for downloading\n",
    "\n",
    "\"\"\"\n",
    "this function returns a set of tuples that are pair of filename and their file ids\n",
    "set : (tuple(file_id,file_name),...)\n",
    "files to download in a collection item are located in the following fields:\n",
    "uploadedFile, extractedText, pages, image, text, ocr, additionalFiles\n",
    "\"\"\"\n",
    "\n",
    "def get_set(items_list:list):\n",
    "    ids=set()\n",
    "    for values in items_list:\n",
    "        #getting the file ids in uploadedFile, extractedText, pages, image, text, ocr, additionalFiles\n",
    "        ids.add((values[\"uploadedFile\"][\"id\"],values[\"uploadedFile\"][\"filename\"]))\n",
    "        if values[\"extractedText\"] and values[\"extractedText\"]!= \"None\":\n",
    "            ids.add((values[\"extractedText\"][\"id\"],values[\"extractedText\"][\"filename\"]))\n",
    "        if values[\"pages\"] and values[\"pages\"] != \"None\":\n",
    "            for value in values[\"pages\"]:\n",
    "                ids.add((value[\"image\"][\"id\"],value[\"image\"][\"filename\"]))\n",
    "                ids.add((value[\"text\"][\"id\"],value[\"text\"][\"filename\"]))\n",
    "                ids.add((value[\"ocr\"][\"id\"],value[\"ocr\"][\"filename\"]))\n",
    "                for file in value[\"additionalFiles\"]:\n",
    "                    ids.add((file[\"id\"],file[\"filename\"]))\n",
    "    return ids\n",
    "   \n",
    "#Create the CSV file with all the metadata and file path of the downloaded files.\n",
    "\n",
    "\"\"\"\n",
    "this function writes the meta data to the csv file.\n",
    "uses a flag to write the fileds at the top of the file in the first time.\n",
    "\"\"\"\n",
    "\n",
    "def write_to_csv(csv_name:str,item:list,flag:int):\n",
    "    with open(csv_name, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if flag==0:\n",
    "            fields = list(item.keys())\n",
    "            writer.writerow(list(fields))\n",
    "        writer.writerow(list(item.values()))\n",
    "        \n",
    "# Add the item to csv_dict that contains all the collection items(with metadata and downloaded file path)\n",
    "\n",
    "\"\"\"\n",
    "adds items to a dictionary object; csv_dict \n",
    "with the collection items unique key as the key for the dictionary\n",
    "and the item dictionary as the value for the respective key, \n",
    "that contains our fields and value/metadata for a\n",
    "given collection item that we write to the csv file. \n",
    "It also adds a path property that indicates the location of the downloades files(if any)\n",
    "\"\"\"\n",
    "\n",
    "def add_to_csv(csv_name:str,folder_name:str, items:list,csv_dict:dict,flag:int):\n",
    "    for item in items[\"items\"]:\n",
    "        if item[\"key\"] in csv_dict:\n",
    "            continue\n",
    "        item[\"path\"] = \"\"\n",
    "        if item[\"gilesUploads\"]:\n",
    "            giles_ids = get_set(item[\"gilesUploads\"])\n",
    "            if giles_ids:\n",
    "                item[\"path\"] = download_file(folder_name, giles_ids, auth_object.access_token)\n",
    "        csv_dict[item[\"key\"]] = item\n",
    "        write_to_csv(csv_name,item,flag)\n",
    "        flag = 1\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "229c7e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#downloads and generate a csv file containing all the group items information\n",
    "def process_groups(csv_name:str,folder_path:str,groups:list, connector, max_size:int):\n",
    "    csv_dict = {}\n",
    "    flag = 0\n",
    "    for group in groups:\n",
    "        group_id = group[\"id\"]\n",
    "        collections = connector.get_collections(group_id)\n",
    "        \n",
    "        for collection in collections[\"collections\"]:\n",
    "            num_pages = math.ceil(collection[\"numberOfItems\"] / max_size)\n",
    "\n",
    "            if num_pages == 1:\n",
    "                items = connector.get_collection_items_pg(group_id, collection[\"key\"], 1)\n",
    "                flag = add_to_csv(csv_name, folder_path, items, csv_dict, flag)\n",
    "            elif num_pages > 1:\n",
    "                for page in range(num_pages):\n",
    "                    items = connector.get_collection_items_pg(group_id, collection[\"key\"], page + 1)\n",
    "                    flag = add_to_csv(csv_name, folder_path, items, csv_dict, flag)\n",
    "\n",
    "    return csv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42eaa42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_filename = \"citesphere_csv.csv\"\n",
    "\n",
    "folder_path  = \"Files\"\n",
    "\n",
    "process_groups(csv_filename,folder_path,groups,connector,max_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
